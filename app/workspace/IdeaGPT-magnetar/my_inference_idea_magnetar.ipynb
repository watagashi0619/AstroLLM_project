{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import getpass\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "#set openAI api key\n",
    "#os.environ[\"OPENAI_API_KEY\"] = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from langchain.document_loaders import DataFrameLoader\n",
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "from langchain.vectorstores import Chroma\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "from langchain.llms import OpenAI\n",
    "from langchain.chains import ConversationalRetrievalChain\n",
    "\n",
    "from langchain.chains.chat_vector_db.prompts import CONDENSE_QUESTION_PROMPT\n",
    "from typing import List\n",
    "from langchain.docstore.document import Document\n",
    "from langchain.document_loaders.base import BaseLoader\n",
    "from langchain.document_loaders import DataFrameLoader\n",
    "import json\n",
    "from langchain.vectorstores import Pinecone\n",
    "# LLM wrapper\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain import OpenAI\n",
    "\n",
    "from langchain import SerpAPIWrapper, LLMChain\n",
    "from langchain.chains.question_answering import load_qa_chain\n",
    "from langchain.memory import ConversationSummaryBufferMemory\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "import pandas as pd\n",
    "# Helper function for printing docs\n",
    "import textwrap\n",
    "\n",
    "def pretty_text(text):\n",
    "    wrapped_text = textwrap.wrap(text, width=100)\n",
    "    for line in wrapped_text:\n",
    "        print(line)\n",
    "\n",
    "\n",
    "def pretty_print_docs(docs):\n",
    "    print(f\"\\n{'-' * 100}\\n\".join([f\"Document {i+1}:\\n\\n\" + d.page_content for i, d in enumerate(docs)]))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_embedding_db(index_name):\n",
    "    from langchain.vectorstores import FAISS\n",
    "    # You may need to import the embeddings model depending on your application's structure\n",
    "    # from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "    embeddings = OpenAIEmbeddings()\n",
    "    db = FAISS.load_local(index_name, embeddings)\n",
    "    return db\n",
    "\n",
    "#db = load_embedding_db(\"faiss_index_1000_200_1000papers\")\n",
    "#db = load_embedding_db(\"faiss_index_1000\")\n",
    "db = load_embedding_db(\"faiss_index_1000_magnetar_OR_fast_radio_burst\")\n",
    "retriever = db.as_retriever(\n",
    "    search_kwargs={\"k\":100, \"include_metadata\": True})\n",
    "#retriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_transformers import EmbeddingsRedundantFilter\n",
    "from langchain.retrievers.document_compressors import DocumentCompressorPipeline\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "from langchain.llms import OpenAI\n",
    "from langchain.retrievers import ContextualCompressionRetriever\n",
    "from langchain.retrievers.document_compressors import LLMChainExtractor, LLMChainFilter\n",
    "from langchain.retrievers.document_compressors import EmbeddingsFilter\n",
    "\n",
    "embeddings = OpenAIEmbeddings()\n",
    "# ドキュメントを小さな塊に分割する\n",
    "# splitter = CharacterTextSplitter(chunk_size=1000, chunk_overlap=100, separator=\". \")\n",
    "# 冗長ドキュメントを削除するフィルター\n",
    "# redundant_filter = EmbeddingsRedundantFilter(embeddings=embeddings)\n",
    "# 類似度フィルター\n",
    "relevant_filter = EmbeddingsFilter(embeddings=embeddings, similarity_threshold=0.76)\n",
    "# パイプラインでスプリッターとフィルターを繋ぐ。transformers=[splitter, redundant_filter, relevant_filter]とかにする\n",
    "pipeline_compressor = DocumentCompressorPipeline(\n",
    "    transformers=[relevant_filter]\n",
    ")\n",
    "\n",
    "compression_retriever = ContextualCompressionRetriever(base_compressor=pipeline_compressor, base_retriever=retriever)\n",
    "\n",
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "prompt_template = \"\"\"\n",
    "You are Dr. Origins, a specialist in observational studies of magnetars. Your expertise lies in reading and critically interpreting astronomy papers to generate innovative, research-based ideas.\n",
    "Every idea should commence with \"I propose...\".\n",
    "\n",
    "Guidelines:\n",
    "1. Base your ideas on scientifically recognized theories and principles.\n",
    "2. Your ideas should be feasibly verifiable and provide avenues for further exploration or research in this field.\n",
    "3. Abstain from making overly speculative claims or assertions that cannot be empirically tested.\n",
    "4. Always accurately reference established theories, observational data, or universally accepted astronomical concepts. Do not misrepresent or fabricate scientific references. If you are unsure about a reference, do not use it.\n",
    "5. Clearly distinguish your ideas from referenced material. Explain how the referenced research inspired your idea.\n",
    "6. Learn from feedback. Improve and adjust your proposal according to received input.\n",
    "7. Use less than 250 words.\n",
    "In response to a human query, generate an informed, precise, and critical response, ensuring your answer's clarity and originality.\n",
    "\n",
    "Context: {context}\n",
    "Human: {question}\n",
    "Dr. Origins: \"\"\"\n",
    " \n",
    "\n",
    "DRC_PROMPT = PromptTemplate(\n",
    "    template=prompt_template, input_variables=[\"context\", \"question\"]\n",
    ")\n",
    "\n",
    "#citationありだと何故かエラーを吐いたので消した\n",
    "doc_template = \"\"\"--- document start ---\n",
    "content:{page_content}\n",
    "--- document end ---\n",
    "\"\"\"\n",
    "\n",
    "ASTRO_DOC_PROMPT = PromptTemplate(\n",
    "    template=doc_template,\n",
    "    input_variables=[\"page_content\"],\n",
    ")\n",
    "\n",
    "from langchain.chains import TransformChain, LLMChain, SimpleSequentialChain\n",
    "\n",
    "model_name = \"gpt-4\"\n",
    "llm_qg = ChatOpenAI(temperature=0.2, model_name=model_name)\n",
    "\n",
    "\n",
    "TEMP = 0.7\n",
    "llm = ChatOpenAI(temperature=TEMP, model_name=model_name)\n",
    "\n",
    "# CONDENSE_QUESTION_PROMPT はここまでの履歴を要約してプロンプトを入れてくれるらしい\n",
    "question_generator = LLMChain(llm=llm_qg, prompt=CONDENSE_QUESTION_PROMPT) # this is the question generator, i probably need to change it to another model instance\n",
    "\n",
    "#chain_type=\"stuff\", 詰め込み方式 関連するデータをすべて詰め込む\n",
    "doc_chain = load_qa_chain(\n",
    "    llm=llm, \n",
    "    chain_type=\"stuff\", \n",
    "    prompt=DRC_PROMPT, \n",
    "    document_prompt=ASTRO_DOC_PROMPT\n",
    ")\n",
    "\n",
    "memory = ConversationSummaryBufferMemory(llm=llm, memory_key=\"chat_history\", return_messages=True, output_key=\"answer\")\n",
    "\n",
    "app_retriever = compression_retriever\n",
    "\n",
    "chain = ConversationalRetrievalChain(\n",
    "    retriever=app_retriever,\n",
    "    question_generator=question_generator,\n",
    "    combine_docs_chain=doc_chain,\n",
    "    memory=memory,\n",
    "    return_source_documents=True,\n",
    "    max_tokens_limit=7000,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"\"\"\n",
    "In the field of magnetar research, the relationship between magnetar and fast radio bursts, and how much magnetar is contained in fast radio bursts, are now the focus of much attention. What kind of observation proposals would be effective for observational research using satellites such as JWST (optical), NuSTAR (hard X-ray), and NICER (soft X-ray)?\n",
    "\"\"\"\n",
    "result = chain({\"question\": query})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = dict()\n",
    "tmp[\"question\"] = result[\"question\"]\n",
    "tmp[\"answer\"] = result[\"answer\"]\n",
    "tmp[\"source_documents\"] = []\n",
    "for item in result[\"source_documents\"]:\n",
    "    tmp2 = dict()\n",
    "    tmp2[\"metadata\"] = item.metadata\n",
    "    tmp2[\"page_content\"] = item.page_content\n",
    "    tmp[\"source_documents\"].append(tmp2)\n",
    "if not os.path.exists(\"results\"):\n",
    "    os.makedirs(\"results\")\n",
    "with open(f'./results/result_{int(time.time())}_magneter_1000_07_e4_a2.json', 'w') as f:\n",
    "    json.dump(tmp, f, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I propose a multi-wavelength observation campaign to study magnetars and their associated fast radio bursts (FRBs). Based on the mentioned studies, FRBs have been linked to magnetars, but the exact mechanism of their emission is still unclear. \n",
      "\n",
      "1. We could use the NuSTAR satellite to observe high-energy X-ray emissions from active magnetars, such as SGR J1935+2154, as it has been suggested that these bursts are linked to FRBs (Ridnaia et al. 2020; Tavani et al. 2020). Observing these bursts could help us understand the energy mechanisms behind FRBs.\n",
      "\n",
      "2. Simultaneously, we could use the NICER satellite to observe the softer X-ray emissions from these magnetars. The correlation between soft X-ray and hard X-ray emissions could provide insight into the magnetar's internal structure and energy distribution.\n",
      "\n",
      "3. In conjunction with these X-ray observations, we could use the JWST to observe the optical emissions from these magnetars, especially during active periods. This could provide additional data on the energy spectrum of these objects and help confirm or disprove theories about the emission mechanisms of FRBs.\n",
      "\n",
      "4. Lastly, to link these observations directly to FRBs, we should coordinate these observations with radio observatories that can detect FRBs. This could allow us to directly correlate observed X-ray and optical emissions with the occurrence of FRBs.\n",
      "\n",
      "This multi-wavelength approach would allow us to observe a broad range of emissions from these magnetars and could potentially provide valuable insights into the mechanisms behind FRBs.\n"
     ]
    }
   ],
   "source": [
    "print(result[\"answer\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I propose a multi-wavelength observation campaign to study magnetars and their associated fast radio\n",
      "bursts (FRBs). Based on the mentioned studies, FRBs have been linked to magnetars, but the exact\n",
      "mechanism of their emission is still unclear.   1. We could use the NuSTAR satellite to observe\n",
      "high-energy X-ray emissions from active magnetars, such as SGR J1935+2154, as it has been suggested\n",
      "that these bursts are linked to FRBs (Ridnaia et al. 2020; Tavani et al. 2020). Observing these\n",
      "bursts could help us understand the energy mechanisms behind FRBs.  2. Simultaneously, we could use\n",
      "the NICER satellite to observe the softer X-ray emissions from these magnetars. The correlation\n",
      "between soft X-ray and hard X-ray emissions could provide insight into the magnetar's internal\n",
      "structure and energy distribution.  3. In conjunction with these X-ray observations, we could use\n",
      "the JWST to observe the optical emissions from these magnetars, especially during active periods.\n",
      "This could provide additional data on the energy spectrum of these objects and help confirm or\n",
      "disprove theories about the emission mechanisms of FRBs.  4. Lastly, to link these observations\n",
      "directly to FRBs, we should coordinate these observations with radio observatories that can detect\n",
      "FRBs. This could allow us to directly correlate observed X-ray and optical emissions with the\n",
      "occurrence of FRBs.  This multi-wavelength approach would allow us to observe a broad range of\n",
      "emissions from these magnetars and could potentially provide valuable insights into the mechanisms\n",
      "behind FRBs.\n"
     ]
    }
   ],
   "source": [
    "pretty_text(result[\"answer\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
